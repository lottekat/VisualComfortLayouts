{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFKav4aQOiuF"
      },
      "source": [
        "##Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCxH9kutODAE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "\n",
        "import shapely.geometry as sg\n",
        "import shapely.wkt\n",
        "from shapely.geometry import Polygon, MultiPolygon, box, LineString, Point\n",
        "from shapely.ops import transform , unary_union, cascaded_union, linemerge\n",
        "from shapely import affinity\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.colors import ListedColormap, Normalize, BoundaryNorm, TwoSlopeNorm\n",
        "from matplotlib.collections import PatchCollection\n",
        "from matplotlib.cm import ScalarMappable, RdYlGn\n",
        "\n",
        "from skimage import measure\n",
        "\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "from ipywidgets import widgets\n",
        "import time\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1mHhMXl0Ru_"
      },
      "source": [
        "## Import dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO8HQffUxQUv"
      },
      "source": [
        "Create dataframes for geometry and simulation results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw1saXYzxONV"
      },
      "outputs": [],
      "source": [
        "#Create geometry dataframe\n",
        "#Call CSV file of dataset, and import dataset using Pandas\n",
        "path_geom = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/Swiss Dataset/SwissDataset_v3.0.0/SwissDataset_v3.0.0_geometries.csv'\n",
        "Swiss_geom = pd.read_csv(path_geom)\n",
        "\n",
        "#Create (pandas) dataframe\n",
        "df_geom_tot = pd.DataFrame(Swiss_geom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oMfZDSV0PLl"
      },
      "outputs": [],
      "source": [
        "#Create simulation dataframe\n",
        "#Call CSV file of dataset, and import dataset using Pandas\n",
        "path_sim = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/Swiss Dataset/SwissDataset_v3.0.0/SwissDataset_v3.0.0_simulations.csv'\n",
        "Swiss_sim = pd.read_csv(path_sim)\n",
        "\n",
        "#Create (pandas) dataframe\n",
        "df_sim = pd.DataFrame(Swiss_sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGRUjTxhAwpo",
        "outputId": "dba0b5e0-ef3f-4623-ecbd-e7defd4f96a6"
      },
      "outputs": [],
      "source": [
        "#Drop duplicates\n",
        "df_sim = df_sim.drop_duplicates()\n",
        "df_geom_tot = df_geom_tot.drop_duplicates()\n",
        "\n",
        "#Filter out features\n",
        "df_geom_tot = df_geom_tot[df_geom_tot[\"entity_type\"] != \"feature\"]\n",
        "\n",
        "## Remove the apartments with multiple floors -> outside scope of thesis\n",
        "# Count the number of unique unit_ids per apartment_id\n",
        "apartment_unit_counts = df_geom_tot.groupby('apartment_id')['unit_id'].nunique()\n",
        "\n",
        "# Get the apartment_ids with multiple unique unit_ids\n",
        "apartments_with_multiple_floors = apartment_unit_counts[apartment_unit_counts > 1].index\n",
        "\n",
        "# Remove rows with apartment_ids that have multiple unique unit_ids\n",
        "df_geom_tot = df_geom_tot[~df_geom_tot['apartment_id'].isin(apartments_with_multiple_floors)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k5cJeXRGkgK"
      },
      "outputs": [],
      "source": [
        "#Reduce the number of varables in entity_subtype, separators\n",
        "df_geom_tot.loc[df_geom_tot['entity_subtype'] == 'COLUMN', 'entity_subtype'] = 'WALL'\n",
        "df_geom_tot.loc[df_geom_tot['entity_subtype'] == 'ENTRANCE_DOOR', 'entity_subtype'] = 'DOOR'\n",
        "\n",
        "# Put all the outdoor spaces under one name\n",
        "categories_to_outdoor = ['BALCONY', 'LOGGIA', 'TERRACE', 'WINTERGARTEN', 'PATIO', 'GARDEN', 'RAILING']\n",
        "for category in categories_to_outdoor:\n",
        "    df_geom_tot.loc[df_geom_tot['entity_subtype'] == category, 'entity_subtype'] = 'OUTDOOR_SPACE'\n",
        "df_geom_tot.loc[df_geom_tot['entity_subtype'] == 'RAILING', 'entity_subtype'] = 'OUTDOOR_SPACE'\n",
        "\n",
        "# Put all the living space functions under one name\n",
        "categories_to_living = ['LIVING_DINING', 'DINING', 'KITCHEN_DINING']\n",
        "for category in categories_to_living:\n",
        "    df_geom_tot.loc[df_geom_tot['entity_subtype'] == category, 'entity_subtype'] = 'DINING'\n",
        "\n",
        "#Reduce the number of varables in entity_subtype, separators\n",
        "df_geom_tot.loc[df_geom_tot['entity_subtype'] == 'COLUMN', 'entity_subtype'] = 'WALL'\n",
        "df_geom_tot.loc[df_geom_tot['entity_subtype'] == 'ENTRANCE_DOOR', 'entity_subtype'] = 'DOOR'\n",
        "\n",
        "# Put all the other functions under one name\n",
        "categories_to_other = ['SHAFT', 'NOT_DEFINED']\n",
        "for category in categories_to_other:\n",
        "    df_geom_tot.loc[df_geom_tot['entity_subtype'] == category, 'entity_subtype'] = 'OTHER'\n",
        "\n",
        "# Put all the other functions under one name\n",
        "categories_to_void = ['OUTDOOR_VOID', 'LIGHTWELL', 'VOID']\n",
        "for category in categories_to_void:\n",
        "    df_geom_tot.loc[df_geom_tot['entity_subtype'] == category, 'entity_subtype'] = 'VOID'\n",
        "\n",
        "# Put all the circulation functions under one name\n",
        "categories_to_circulation = ['ELEVATOR', 'CORRIDORS_AND_HALLS', 'ELEVATOR_FACILITIES', 'STAIRCASE']\n",
        "for category in categories_to_circulation:\n",
        "    df_geom_tot.loc[df_geom_tot['entity_subtype'] == category, 'entity_subtype'] = 'CIRCULATION'\n",
        "\n",
        "# Put all the public functions under one name\n",
        "categories_to_public = ['BASEMENT_COMPARTMENT', 'OFFICE', 'PRAM', 'PRAM_AND_BIKE_STORAGE_ROOM', \n",
        "                        'BIKE_STORAGE', 'COUNTER_ROOM', 'BASEMENT', 'TECHNICAL_AREA', 'HEATING',  'WASH_AND_DRY_ROOM',\n",
        "                        'CLOAKROOM', 'SALESROOM', 'GARAGE', 'OIL_TANK', 'HOUSE_TECHNICS_FACILITIES', 'OFFICE_SPACE',\n",
        "                        'OFFICE_TECH_ROOM', 'WAREHOUSE', 'CARPARK', 'SANITARY_ROOMS', 'OPEN_PLAN_OFFICE', 'MEETING_ROOM',\n",
        "                        'BREAK_ROOM', 'ARCHIVE', 'ELECTRICAL_SUPPLY', 'MEDICAL_ROOM', 'WAITING_ROOM', 'COMMON_KITCHEN',\n",
        "                        'VEHICLE_TRAFFIC_AREA', 'AIR', 'FACTORY_ROOM', 'RECEPTION_ROOM', 'COMMUNITY_ROOM', 'WORKSHOP',\n",
        "                        'CANTEEN', 'SHELTER', 'COLD_STORAGE', 'TRANSPORT_SHAFT', 'RADATION_THERAPY', 'PHYSIO_AND_REHABILITATION',\n",
        "                        'WATER_SUPPLY', 'DEDICATED_MEDICAL_ROOM', 'SPORTS_ROOMS', 'SHOWROOM', 'GAS', 'TEACHING_ROOM', 'ARCADE',\n",
        "                        'LOGISTICS', 'OPERATIONS_FACILITIES', 'LOBBY', 'FOYER']\n",
        "for category in categories_to_public:\n",
        "    df_geom_tot.loc[df_geom_tot['entity_subtype'] == category, 'entity_subtype'] = 'PUBLIC'\n",
        "\n",
        "print(df_geom_tot['entity_subtype'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res_room_type = ['BATHROOM', 'LIVING_ROOM', 'ROOM', 'KITCHEN', 'CORRIDOR', 'DINING', 'STOREROOM', 'BEDROOM', 'STUDIO']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJpne4NFOtpu"
      },
      "source": [
        "#Create dataframe - geometry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsdlMbbF0CKM",
        "outputId": "ca3f4c0b-2a0e-48a6-ef64-7e0fa5b8597a"
      },
      "outputs": [],
      "source": [
        "#Get all the unique site_ids in the dataframe\n",
        "unique_site_ids = df_geom_tot['site_id'].unique().tolist()\n",
        "\n",
        "# Specify the number of unique site IDs per sublist -> 100 sites cause this is what's possible to loop through in one day\n",
        "num_per_sublist = 100\n",
        "\n",
        "# Create separate lists for each subset\n",
        "for i in range(0, len(unique_site_ids), num_per_sublist):\n",
        "    sublist = unique_site_ids[i:i+num_per_sublist]\n",
        "    sublist_name = f\"site_ids_{i+num_per_sublist}\"\n",
        "    globals()[sublist_name] = sublist\n",
        "\n",
        "    # Print the current subset\n",
        "    print(f\"Subset: {sublist_name} -> {sublist}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR8DaV670Inr",
        "outputId": "875b72f4-8003-408c-9199-23e595aad8ec"
      },
      "outputs": [],
      "source": [
        "# Assign site_ids_100 to the sublist variable\n",
        "number = 700\n",
        "sublist = site_ids_700\n",
        "\n",
        "# Filter the DataFrame to include only rows with site_ids_100\n",
        "df_geom = df_geom_tot[df_geom_tot['site_id'].isin(sublist)]\n",
        "\n",
        "# show the filtered DataFrame\n",
        "df_geom.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "begin_num = number - num_per_sublist\n",
        "name = f'{begin_num}-{number}'\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ymgaTh50GpV"
      },
      "source": [
        "1st round of cleaning dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DNxeraXpyOy",
        "outputId": "149a9b64-4b2c-4c27-9340-ff8976f55f4c"
      },
      "outputs": [],
      "source": [
        "print(df_geom['entity_subtype'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gy5cmIu3_grT"
      },
      "outputs": [],
      "source": [
        "# set the \"entity_subtype\" column as a string type\n",
        "df_geom['entity_subtype'] = df_geom['entity_subtype'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8jOMrUm68COY",
        "outputId": "aeb81c58-fce7-4d05-c46d-bc9e398702e5"
      },
      "outputs": [],
      "source": [
        "df_geom.tail(-2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpYm-aOs0Pbf"
      },
      "source": [
        "Create color code & sort dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMqHZDoKPBTs"
      },
      "outputs": [],
      "source": [
        "# Define the desired sort order as a list with corresponding colours\n",
        "# Create a dictionary to map categories to their corresponding colors\n",
        "category_to_color = {\n",
        "                     'OTHER':         '#377080',  # midnight green\n",
        "                     'BATHROOM':      '#65949F',  # blue (munsell)                      \n",
        "                     'ROOM':          '#C2DBDC',  # light blue\n",
        "                     'BEDROOM':       '#C2DBDC',  # light blue\n",
        "                     'VOID':          '#F1FFFA',  # mint cream\n",
        "\n",
        "                     'LIVING_ROOM':   '#F6A96F',  # sandy brown\n",
        "                     'KITCHEN':       '#F7D08A',  # sunset / light yellow\n",
        "                     'DINING':        '#f7bd7d',  # fawn / light orange\n",
        "                     'STOREROOM':     '#F3DFAA',  # vanilla\n",
        "\n",
        "                     'CIRCULATION':   '#B0647E',  # china rose\n",
        "                     'CORRIDOR':      '#D7A6B3',  # orchid pink\n",
        "                     'PUBLIC':        '#F3E2E7',  # lavender blush \n",
        "                     \n",
        "                     'OUTDOOR_SPACE': '#A9D8B0',  # tea green\n",
        "\n",
        "                     'WALL':          '#808081',  #grey\n",
        "                     'DOOR':          '#d3d3d3',  #lightgrey\n",
        "                     'OUTSIDE_DOOR':  '#94BDAA',  #cambridge blue\n",
        "                     'WINDOW':        '#B5E3F1'   #light blue\n",
        "                     }\n",
        "\n",
        "# Extract the categories from the data and map them to their corresponding colors\n",
        "categories = list(category_to_color.keys())\n",
        "colors = list(category_to_color.values())\n",
        "\n",
        "# Create a color map from the used colors\n",
        "color_map = ListedColormap(colors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keyusEtO06xw"
      },
      "source": [
        "2nd round of cleaning datafream\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Create 2 dataframes, one with only residential types, and one with also the\n",
        "public functions present\n",
        "And change dataframes to Geopandas dataframe with usable geometry column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib1mi3xBhkNj",
        "outputId": "d96d052b-42f3-4ebf-978d-1e60c7c1c4c5"
      },
      "outputs": [],
      "source": [
        "#Residential dataframe\n",
        "df_res = df_geom[df_geom[\"unit_usage\"] == \"RESIDENTIAL\"]\n",
        "df_res['outside_connection'] = \"\"\n",
        "df_res['door_connection1'] = \"\"\n",
        "df_res['door_connection2'] = \"\"\n",
        "print(df_res['entity_subtype'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX2VaIAMLwEP",
        "outputId": "97855221-8e11-4456-e8fd-15a355acc2e6"
      },
      "outputs": [],
      "source": [
        "df_res.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA6oOXsR7Jtp"
      },
      "outputs": [],
      "source": [
        "#Create geoseries with polygons -> change wkt to polygon\n",
        "# Check if the 'geometry' column is already a GeoSeries object\n",
        "if df_res['geometry'].dtype == 'geometry':\n",
        "  gs_res = df_res['geometry']\n",
        "  gs_geom = df_geom['geometry']\n",
        "else:\n",
        "  gs_res = gpd.GeoSeries.from_wkt(df_res['geometry'])\n",
        "  gs_geom = gpd.GeoSeries.from_wkt(df_geom['geometry'])\n",
        "\n",
        "#Create new Geodataframes with polygons\n",
        "gdf_res = gpd.GeoDataFrame(df_res, geometry=gs_res, crs=None)\n",
        "gdf_geom = gpd.GeoDataFrame(df_geom, geometry=gs_geom, crs=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lpaSpuDOIoab",
        "outputId": "3383b664-5e94-4f1c-9dda-9c5dea6a002c"
      },
      "outputs": [],
      "source": [
        "gdf_res.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5iZlNnTy98h"
      },
      "source": [
        "#Create dataframe - simulation results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "E3gEp4DEiWIm",
        "outputId": "3def77ab-e68b-4d9d-848f-3fd24303f662"
      },
      "outputs": [],
      "source": [
        "#Create df with information needed out simulation cvs\n",
        "df_sim_info = df_sim.loc[:, ['area_id', 'apartment_id', 'layout_area','layout_perimeter', 'layout_biggest_rectangle_length', 'layout_biggest_rectangle_width']]\n",
        "\n",
        "# Calculate the room depth ratio\n",
        "df_sim_info['room_depth_ratio'] = (df_sim_info['layout_biggest_rectangle_length'] / df_sim_info['layout_biggest_rectangle_width']).round(3)\n",
        "\n",
        "df_sim_info.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2SxUbYpfxtw"
      },
      "source": [
        "##Create dataframe to start storing all needed information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "TrKKJLlefvAY",
        "outputId": "07ac0abf-f6e0-4399-f5f6-5742e7902910"
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe with desired columns\n",
        "# Create a new dataframe with desired columns and filter conditions\n",
        "df_info = gdf_res[(gdf_res['entity_type'] == 'area') | (gdf_res['entity_subtype'] == 'WINDOW') | (gdf_res['entity_subtype'] == 'DOOR')].copy()\n",
        "df_info = df_info[['apartment_id', 'site_id', 'area_id', 'entity_subtype', 'geometry', 'elevation', 'height', 'outside_connection', 'door_connection1', 'door_connection2']]\n",
        "\n",
        "# Add empty columns for info about window orientation and areas\n",
        "df_info['nr_window_sides'] = \"\"\n",
        "df_info['orientation'] = \"\"\n",
        "df_info['orientation_percentage'] = \"\"\n",
        "df_info['window_height'] = \"\"\n",
        "df_info['window_length'] = \"\"\n",
        "df_info['window_area'] = \"\"\n",
        "df_info['wall_area'] = \"\"\n",
        "df_info['window_wall_ratio'] = \"\"\n",
        "\n",
        "df_info.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_info_doors = df_info[(df_info['entity_subtype'] == 'DOOR')]\n",
        "df_info_doors.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-FroGfkdRfz"
      },
      "source": [
        "#Definitions window orientation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcBnfFcV1Fw1"
      },
      "outputs": [],
      "source": [
        "def point_movement(x1, y1, x2_other, y2_other):\n",
        "  movement = []\n",
        "\n",
        "  if x2_other < x1:\n",
        "    movement.append('right')\n",
        "  if x2_other > x1:\n",
        "    movement.append('left')\n",
        "  if x2_other == x1:\n",
        "    movement.append('no')\n",
        "\n",
        "  if y2_other < y1:\n",
        "    movement.append('top')\n",
        "  if y2_other > y1:\n",
        "    movement.append('down')\n",
        "  if y2_other == y1:\n",
        "    movement.append('no')\n",
        "\n",
        "  return movement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOSu-byX-Xez"
      },
      "outputs": [],
      "source": [
        "def find_orientation(angle, movement):\n",
        "  # Angle North and South\n",
        "  if -22.5 <= angle <= 22.5 or 157.5 <= angle or angle <= -157.5:\n",
        "    orientation = 'South' if movement[1] == 'top' else 'North'\n",
        "\n",
        "  # Angle East and West\n",
        "  elif 67.5 <= angle <= 112.5 or -112.5 <= angle <= -67.5:\n",
        "    orientation = 'East' if movement[0] == 'left' else 'West'\n",
        "\n",
        "  # Angle N/S-East and N/S-West\n",
        "  elif (22.5 <= angle <= 67.5 or -157.5 <= angle <= -112.5) and movement[0] == 'left':\n",
        "    orientation = 'South-East' if movement[1] == 'top' else 'North-East'\n",
        "  elif (22.5 <= angle <= 67.5 or -157.5 <= angle <= -112.5) and movement[0] == 'right':\n",
        "    orientation = 'South-West' if movement[1] == 'top' else 'North-West'\n",
        "\n",
        "  # Angle N/S-East and N/S-West\n",
        "  elif (112.5 <= angle <= 157.5 or -67.5 <= angle <= -22.5) and movement[0] == 'left':\n",
        "    orientation = 'South-East' if movement[1] == 'top' else 'North-East'\n",
        "  elif (112.5 <= angle <= 157.5 or -67.5 <= angle <= -22.5) and movement[0] == 'right':\n",
        "    orientation = 'South-West' if movement[1] == 'top' else 'North-West'\n",
        "\n",
        "  else:\n",
        "    orientation = f'other_{angle}_{movement}'\n",
        "\n",
        "  return orientation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBOVJbBHaGlM"
      },
      "outputs": [],
      "source": [
        "def window_line_length(window):\n",
        "    #create empty list to store data\n",
        "    longest_lines = []\n",
        "\n",
        "    #Get the 4 window sides of polygon\n",
        "    coords = window.exterior.coords\n",
        "    line1 = LineString([coords[0], coords[1]])\n",
        "    line2 = LineString([coords[1], coords[2]])\n",
        "    line3 = LineString([coords[2], coords[3]])\n",
        "    line4 = LineString([coords[3], coords[0]])\n",
        "\n",
        "    #Get lengths of window sides, and determines longest side = window length\n",
        "    line_lengths = [round(line1.length, 5), round(line2.length, 5), round(line3.length, 5), round(line4.length, 5)]\n",
        "    window_length = max(line_lengths)\n",
        "\n",
        "    #Get geometry of lines\n",
        "    lines_coords = [line1.coords, line2.coords, line3.coords, line4.coords]\n",
        "\n",
        "    #Only store the 2 longest sides of window\n",
        "    for i in range(len(line_lengths)):\n",
        "        if line_lengths[i] == window_length:\n",
        "            longest_lines.append(lines_coords[i])\n",
        "\n",
        "    return window_length, longest_lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def small_window_line_length(window):\n",
        "    #create empty list to store data\n",
        "    longest_lines = []\n",
        "\n",
        "    #Get the 4 window sides of polygon\n",
        "    coords = window.exterior.coords\n",
        "    line1 = LineString([coords[0], coords[1]])\n",
        "    line2 = LineString([coords[1], coords[2]])\n",
        "    line3 = LineString([coords[2], coords[3]])\n",
        "    line4 = LineString([coords[3], coords[0]])\n",
        "\n",
        "    #Get lengths of window sides, and determines longest side = window length\n",
        "    line_lengths = [round(line1.length, 5), round(line2.length, 5), round(line3.length, 5), round(line4.length, 5)]\n",
        "    window_length = min(line_lengths)\n",
        "\n",
        "    #Get geometry of lines\n",
        "    lines_coords = [line1.coords, line2.coords, line3.coords, line4.coords]\n",
        "\n",
        "    #Only store the 2 longest sides of window\n",
        "    for i in range(len(line_lengths)):\n",
        "        if line_lengths[i] == window_length:\n",
        "            longest_lines.append(lines_coords[i])\n",
        "\n",
        "    return window_length, longest_lines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdTbAmq8dWwA"
      },
      "source": [
        "#Feature creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUChx60cGO3f"
      },
      "source": [
        "Connect area_ids\n",
        "\n",
        "---\n",
        "1. Find all data per apartment_id\n",
        "2. Loop over rooms in apartment\n",
        "3. Buffer room to find geometry that belongs to room\n",
        "4. Append area_id of room to the windows and doors belonging to the room"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Stop here when half file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V724A74i1S0w",
        "outputId": "3344538d-c94b-4929-d86d-ee1805db9135"
      },
      "outputs": [],
      "source": [
        "#To try for one apartment\n",
        "#app_ids = ['0a31e9e1152f226e5104ec79b726f052', '0ec0791b6c93b251a33f6289947f1f5d', '2aa789e7bf1114b4832b65c36e67b161', '2bbae2c8871ae1b111db2974347b8d28', '05d19084d6b9d308a4cfda040ee77c2b', '26dec908c4bd5d336c67ee41f5dade93', '062b1890c079f88c174b203fe83a92f2', 'd8e7ec1637e4822c3080085ac030bed6']\n",
        "#app_ids = ['d8e7ec1637e4822c3080085ac030bed6']\n",
        "#for app_id in app_ids:\n",
        "\n",
        "# Locate rows where entity_subtype is 'WINDOW' and area_id is NaN\n",
        "filtered_df = gdf_res[(gdf_res['entity_subtype'] == 'WINDOW') & pd.isnull(gdf_res['area_id'])]\n",
        "print(len(filtered_df['apartment_id'].unique()))\n",
        "\n",
        "for app_id in filtered_df['apartment_id'].unique():\n",
        "\n",
        "  #Get dataframe of apartment in which room lies, to find unique area_ids\n",
        "  gdf_apartment = gdf_res.loc[gdf_res[\"apartment_id\"]== app_id]\n",
        "\n",
        "  # Combine area geometries and buffer them\n",
        "  area_geometries = gdf_apartment[gdf_apartment['entity_type'] == 'area']['geometry']\n",
        "  buffered_geometries = area_geometries.buffer(0.8)\n",
        "  combined_geometry = buffered_geometries.unary_union\n",
        "\n",
        "  # Check windows outside the combined geometry and update area_id\n",
        "  mask = (gdf_apartment['entity_subtype'] == 'WINDOW') & (gdf_apartment['area_id'].isna())\n",
        "  outside_windows = gdf_apartment[mask].loc[~gdf_apartment[mask].geometry.within(combined_geometry)]\n",
        "  gdf_apartment.loc[outside_windows.index, 'area_id'] = 'OUTSIDE'\n",
        "\n",
        "  #To check if it is correct on image\n",
        "  #gdf_apartment.plot(column='entity_subtype', cmap=color_map, legend=False, figsize=(10,10), categories=categories)\n",
        "  unique_area_ids = gdf_apartment.loc[gdf_apartment['entity_type'] == 'area', 'area_id'].unique()\n",
        "\n",
        "  for area_id in unique_area_ids:\n",
        "    #locate the specific apartement in the dataframe\n",
        "    gdf_room = gdf_apartment.loc[gdf_apartment[\"area_id\"]== area_id]\n",
        "\n",
        "    # check if the dataframe is not empty\n",
        "    if not gdf_room.empty:\n",
        "\n",
        "      #Find all the geomerties that belong to the room\n",
        "      gdf_room[\"geometry_buffered\"] = gdf_room[\"geometry\"].buffer(0.8)\n",
        "      gdf_room_complete = gdf_apartment[gdf_apartment.geometry.within(gdf_room[\"geometry_buffered\"].geometry.iloc[0])]\n",
        "\n",
        "      #Connect the windows to the room with the area_id\n",
        "      if gdf_apartment.loc[gdf_apartment[\"area_id\"]== area_id, 'entity_subtype'].isin(res_room_type).any():\n",
        "        gdf_room_complete.loc[gdf_room_complete['entity_subtype'] == 'WINDOW', 'area_id'] = area_id\n",
        "\n",
        "      # Add area_ids to the leftover windows connected to an outdoor space\n",
        "      if gdf_apartment.loc[gdf_apartment[\"area_id\"]== area_id, 'entity_subtype'].isin(['OUTDOOR_SPACE']).any():\n",
        "          mask = (gdf_room_complete['entity_subtype'] == 'WINDOW') & (gdf_room_complete['area_id'].isna())\n",
        "          gdf_room_complete.loc[mask, 'area_id'] = area_id\n",
        "\n",
        "\n",
        "      # Connect the doors to the room with the area_id\n",
        "      door_rows = gdf_room_complete.loc[gdf_room_complete['entity_subtype'] == 'DOOR']\n",
        "\n",
        "      for index, row in door_rows.iterrows():\n",
        "        if row['door_connection1'] == '':\n",
        "          gdf_room_complete.at[index, 'door_connection1'] = area_id \n",
        "\n",
        "        elif row['door_connection2'] == '':\n",
        "          gdf_room_complete.at[index, 'door_connection2'] = area_id \n",
        "\n",
        "        if gdf_apartment.loc[gdf_apartment[\"area_id\"]== area_id, 'entity_subtype'].isin(['OUTDOOR_SPACE']).any():\n",
        "          gdf_room_complete.at[index, 'outside_connection'] = area_id\n",
        "\n",
        "      columns_to_update = ['area_id', 'outside_connection', 'door_connection1', 'door_connection2']\n",
        "\n",
        "      # Update gdf_apartment, df_info, and df_res with values from gdf_room_complete\n",
        "      for column in columns_to_update:\n",
        "        gdf_apartment.update(gdf_room_complete[[column]])\n",
        "        gdf_res.update(gdf_room_complete[[column]])\n",
        "        df_info.update(gdf_room_complete[[column]])\n",
        "        \n",
        "        \n",
        "    else:\n",
        "      print('SKIP, empty')\n",
        "\n",
        "    #To check values per apartment\n",
        "    #print(gdf_apartment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace entity_subtype with 'OUTSIDE_DOOR' based on conditions in df_info\n",
        "df_info.loc[((df_info['entity_subtype'] == 'DOOR') & (df_info['outside_connection'] != '')), 'entity_subtype'] = 'OUTSIDE_DOOR'\n",
        "df_info_doors = df_info[(df_info['entity_subtype'] == 'OUTSIDE_DOOR')]\n",
        "\n",
        "for index, row in df_info_doors.iterrows():\n",
        "    if row['door_connection1'] != row['outside_connection']:\n",
        "        area_id_door = row['door_connection1']\n",
        "        df_info.at[index, 'area_id'] = area_id_door\n",
        "    elif row['door_connection2'] != row['outside_connection']:\n",
        "        area_id_door = row['door_connection2']\n",
        "        df_info.at[index, 'area_id'] = area_id_door"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace entity_subtype with 'OUTSIDE_DOOR' based on conditions in df_res\n",
        "gdf_res.loc[((gdf_res['entity_subtype'] == 'DOOR') & (gdf_res['outside_connection'] != '')), 'entity_subtype'] = 'OUTSIDE_DOOR'\n",
        "gdf_res_doors = gdf_res[(gdf_res['entity_subtype'] == 'OUTSIDE_DOOR')]\n",
        "\n",
        "for index, row in gdf_res_doors.iterrows():\n",
        "    if row['door_connection1'] != row['outside_connection']:\n",
        "        area_id_door = row['door_connection1']\n",
        "        gdf_res.at[index, 'area_id'] = area_id_door\n",
        "    elif row['door_connection2'] != row['outside_connection']:\n",
        "        area_id_door = row['door_connection2']\n",
        "        gdf_res.at[index, 'area_id'] = area_id_door"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_info_doors = df_info[(df_info['entity_subtype'] == 'DOOR')]\n",
        "\n",
        "path_half_doors = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/Swiss Dataset/SwissDataset_v3.0.0/InfoDataCSV_v2/SwissDataset_v3.0.0_info_{name}sites_halfdoors.csv'\n",
        "df_info_doors.to_csv(path_half_doors, index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_info = df_info[(df_info['entity_subtype'] != 'DOOR')]\n",
        "print(df_info['entity_subtype'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the DataFrame to an Excel CSV file\n",
        "path_half = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/Swiss Dataset/SwissDataset_v3.0.0/InfoDataCSV_v2/SwissDataset_v3.0.0_info_{name}sites_half.csv'\n",
        "df_info.to_csv(path_half, index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3USM8qSljsgr"
      },
      "outputs": [],
      "source": [
        "HARD STOP -> manual check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oogEwEWQ_r3S"
      },
      "outputs": [],
      "source": [
        "#1. First check\n",
        "df_info_uncomplete = df_info.loc[df_info['area_id'].isna()]\n",
        "unsucessful_ids = df_info_uncomplete['apartment_id'].unique()\n",
        "print(len(unsucessful_ids))\n",
        "unsucessful_ids_15 = unsucessful_ids[:15]\n",
        "\n",
        "wrong_ids_list = []\n",
        "\n",
        "fig_size = (8, 8)  # Specify the figure size here\n",
        "\n",
        "# Define button click event handlers with closures\n",
        "def create_handler(wrong_code):\n",
        "    def on_button_clicked(b):\n",
        "        wrong_ids_list.append(wrong_code)\n",
        "\n",
        "    return on_button_clicked\n",
        "\n",
        "# Define a function to process apartments\n",
        "def process_apartments():\n",
        "    for app_id in unsucessful_ids_15:\n",
        "        # Get dataframe of apartment in which room lies, to find unique area_ids\n",
        "        gdf_apartment = gdf_res.loc[gdf_res[\"apartment_id\"] == app_id]\n",
        "        room_wrong_geom = df_info_uncomplete[df_info_uncomplete['apartment_id'] == app_id]\n",
        "\n",
        "        nan_count = room_wrong_geom.shape[0]\n",
        "        outside_count = df_info[(df_info['apartment_id'] == app_id) & (df_info['area_id'] == 'OUTSIDE')].shape[0]\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=fig_size)  # Set the figure size\n",
        "\n",
        "        gdf_apartment.plot(column='entity_subtype', cmap=color_map, legend=False, ax=ax, categories=categories)\n",
        "        \n",
        "        # Plot df_info_uncomplete in red\n",
        "        room_wrong_geom.plot(ax=ax, color='red')\n",
        "\n",
        "        plt.title(f\"{app_id} ({nan_count} NaN, {outside_count} outside)\")\n",
        "\n",
        "        # Create button widgets\n",
        "        wrong1_button = widgets.Button(description=\"shared window/door\")\n",
        "        wrong2_button = widgets.Button(description=\"outside apartment\")\n",
        "        wrong3_button = widgets.Button(description=\"other problem\")\n",
        "\n",
        "        # Attach button click event handlers\n",
        "        wrong1_button.on_click(create_handler('wrong1'))\n",
        "        wrong2_button.on_click(create_handler('wrong2'))\n",
        "        wrong3_button.on_click(create_handler('wrong3'))\n",
        "\n",
        "        # Create an output widget to display the result\n",
        "        output = widgets.Output()\n",
        "\n",
        "        # Display the buttons and output widget\n",
        "        display(widgets.HBox([wrong1_button, wrong2_button, wrong3_button]))\n",
        "        display(output)\n",
        "\n",
        "        # Display the plot\n",
        "        plt.show()\n",
        "\n",
        "# Run the function to process apartments\n",
        "process_apartments()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(wrong_ids_list)\n",
        "#print(unsucessful_ids_15)\n",
        "\n",
        "wrong1_ids = [] #shared windows\n",
        "wrong2_ids = [] #outside windows\n",
        "wrong3_ids = [] #other reason why wrong\n",
        "\n",
        "for wrong_code, app_id in zip(wrong_ids_list, unsucessful_ids_15):\n",
        "    if wrong_code == 'wrong1':\n",
        "        wrong1_ids.append(app_id)\n",
        "    elif wrong_code == 'wrong2':\n",
        "        wrong2_ids.append(app_id)\n",
        "    elif wrong_code == 'wrong3':\n",
        "        wrong3_ids.append(app_id)\n",
        "\n",
        "print('wrong1', wrong1_ids)\n",
        "print('wrong2', wrong2_ids)\n",
        "print('wrong3', wrong3_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTuPPJskGpuP"
      },
      "outputs": [],
      "source": [
        "mask1 = (df_info['apartment_id'].isin(wrong1_ids)) & ((df_info['entity_subtype'] == 'WINDOW') | (df_info['entity_subtype'] == 'OUTSIDE_DOOR')) & (df_info['area_id'].isna())\n",
        "df_info.loc[mask1, 'area_id'] = 'SHARED'\n",
        "\n",
        "mask2 = (df_info['apartment_id'].isin(wrong2_ids)) & ((df_info['entity_subtype'] == 'WINDOW') | (df_info['entity_subtype'] == 'OUTSIDE_DOOR')) & (df_info['area_id'].isna())\n",
        "df_info.loc[mask2, 'area_id'] = 'OUTSIDE'\n",
        "\n",
        "mask3 = (df_info['apartment_id'].isin(wrong3_ids)) & ((df_info['entity_subtype'] == 'WINDOW') | (df_info['entity_subtype'] == 'OUTSIDE_DOOR')) & (df_info['area_id'].isna())\n",
        "df_info.loc[mask3, 'area_id'] = 'WRONG'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save half way before beginnng next part\n",
        "path_half = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/Swiss Dataset/SwissDataset_v3.0.0/InfoDataCSV_v2/SwissDataset_v3.0.0_info_{name}sites_half.csv'\n",
        "df_info.to_csv(path_half, index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F98qw4RGZRH"
      },
      "source": [
        "Window length & orientation\n",
        "\n",
        "---\n",
        "1. Find all data per apartment_id\n",
        "2. Loop over rooms in apartment based on area_id\n",
        "3. Loop over all windows in room\n",
        "4. Find longest line of window = window_length\n",
        "5. Calculate window angle\n",
        "6. Find movement between 2 longest window lines\n",
        "7. Find correct orientation based on angle and movement\n",
        "8. Append window_length & window_orientation to df_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "#If code does not work any more, continue from half dataframe\n",
        "path_half = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/Swiss Dataset/SwissDataset_v3.0.0/InfoDataCSV_v2/SwissDataset_v3.0.0_info_{name}sites_half.csv'\n",
        "df_info_half = pd.read_csv(path_half, index_col=0)\n",
        "\n",
        "#Create (pandas) dataframe\n",
        "df_info_half = pd.DataFrame(df_info_half)\n",
        "\n",
        "# Add empty columns for info about window orientation and areas\n",
        "df_info = df_info_half\n",
        "\n",
        "df_info['nr_window_sides'] = \"\"\n",
        "df_info['orientation'] = \"\"\n",
        "df_info['orientation_percentage'] = \"\"\n",
        "df_info['window_height'] = \"\"\n",
        "df_info['window_length'] = \"\"\n",
        "df_info['window_area'] = \"\"\n",
        "df_info['wall_area'] = \"\"\n",
        "df_info['window_wall_ratio'] = \"\"\n",
        "\n",
        "\n",
        "columns_to_update = ['area_id', 'outside_connection', 'door_connection1', 'door_connection2']\n",
        "\n",
        "# Update gdf_apartment, df_info, and df_res with values from gdf_room_complete\n",
        "for column in columns_to_update:\n",
        "    gdf_res.update(df_info[[column]]) \n",
        "    \n",
        "gdf_res.drop_duplicates() '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iS2VDC3GFyYQ"
      },
      "outputs": [],
      "source": [
        "#To try for one apartment\n",
        "#app_ids = ['0a31e9e1152f226e5104ec79b726f052', '0ec0791b6c93b251a33f6289947f1f5d', '2aa789e7bf1114b4832b65c36e67b161', '2bbae2c8871ae1b111db2974347b8d28', '05d19084d6b9d308a4cfda040ee77c2b', '26dec908c4bd5d336c67ee41f5dade93', '062b1890c079f88c174b203fe83a92f2', 'd8e7ec1637e4822c3080085ac030bed6']\n",
        "#app_ids = ['f7f2c0f9721bca63a675d423050df29a']\n",
        "\n",
        "window_subtypes = ['WINDOW', 'OUTSIDE_DOOR']\n",
        "\n",
        "# Locate rows where entity_subtype is 'WINDOW' and area_id is NaN\n",
        "filtered_df = df_info[(df_info['entity_subtype'].isin(window_subtypes)) & (df_info['orientation'] == '')]\n",
        "print(len(filtered_df['apartment_id'].unique()))\n",
        "\n",
        "#for app_id in app_ids:\n",
        "for app_id in filtered_df['apartment_id'].unique():\n",
        "  #print(app_id)\n",
        "\n",
        "  #Get dataframe of apartment in which room lies, to find unique area_ids\n",
        "  gdf_apartment = gdf_res.loc[gdf_res[\"apartment_id\"]== app_id]\n",
        "  gdf_apartment_area = gdf_apartment.loc[gdf_apartment[\"entity_type\"]== 'area']\n",
        "  unique_areas = gdf_apartment_area['area_id'].unique()\n",
        "  #print(len(set(unique_areas)))\n",
        "\n",
        "  #To check on image\n",
        "  #gdf_apartment.plot(column='entity_subtype', cmap=color_map, legend=False, figsize=(10,10), categories=categories)\n",
        "  \n",
        "  for area_id in unique_areas:\n",
        "    #print(area_id)\n",
        "\n",
        "    #locate the specific room in the dataframe\n",
        "    gdf_room = gdf_apartment.loc[gdf_apartment[\"area_id\"]== area_id]\n",
        "\n",
        "    # check if the dataframe is not empty and only continue for (bed)rooms, kitchens, bathrooms, living rooms, corridors and stoarge rooms\n",
        "    if ~gdf_room.empty or gdf_room.loc[gdf_room[\"area_id\"]== area_id, 'entity_subtype'].isin(res_room_type).any():\n",
        "\n",
        "      #get geomerty of windows and room\n",
        "      window_polygons = gdf_room.loc[(df_info['entity_subtype'].isin(window_subtypes)), 'geometry']\n",
        "      room_polygons = gdf_room.loc[gdf_room['entity_type'] == 'area', 'geometry']\n",
        "      \n",
        "      if not window_polygons.empty:\n",
        "        #print('use')\n",
        "\n",
        "        #To check on image\n",
        "        #fig, ax = plt.subplots()\n",
        "        \n",
        "        # Buffer room polygon to ensure capturing intersecting window line\n",
        "        buffered_room = room_polygons.buffer(0.05)\n",
        "\n",
        "        #iterate over windows in the room\n",
        "        for index, window in window_polygons.iteritems():\n",
        "          window_length, longest_lines = window_line_length(window)\n",
        "\n",
        "          if window_length < 0.6:\n",
        "              intersection_count = 0\n",
        "\n",
        "              for line in longest_lines:\n",
        "                  line_segment = LineString(line)\n",
        "                  if buffered_room.intersects(line_segment).any():\n",
        "                      intersection_count += 1\n",
        "\n",
        "              if intersection_count > 1:\n",
        "                window_length, longest_lines = small_window_line_length(window)\n",
        "\n",
        "          # check which line intersects with room polygons\n",
        "          for line in longest_lines:\n",
        "            #Get geometry of the line\n",
        "            line_segment = LineString(line)\n",
        "\n",
        "            #Continue only with window line on room side\n",
        "            if buffered_room.intersects(line_segment).any():\n",
        "\n",
        "              #Get window line coordinates\n",
        "              x1, y1 = line_segment.coords[0]\n",
        "              x2, y2 = line_segment.coords[1]\n",
        "\n",
        "              #Calculate angle of the window line\n",
        "              angle = round(math.degrees(math.atan2((y2-y1), (x2-x1))),2)\n",
        "\n",
        "              #Get line coordinates of other line\n",
        "              other_line_coords = [c for c in longest_lines if c != line]\n",
        "              x2_other, y2_other = other_line_coords[0][1]\n",
        "\n",
        "              #Find to movement of other point to window line point\n",
        "              movement = point_movement(x1, y1, x2_other, y2_other)\n",
        "\n",
        "              #determine window orientation based on angle and movement\n",
        "              orientation = find_orientation(angle, movement)\n",
        "\n",
        "              mask = ((df_info.index == index) & (df_info['area_id'] == area_id) & (df_info['entity_subtype'].isin(['WINDOW', 'OUTSIDE_DOOR'])))\n",
        "\n",
        "              df_info.loc[mask, 'orientation'] = orientation\n",
        "              df_info.loc[mask, 'window_length'] = window_length\n",
        "\n",
        "              '''\n",
        "              #To check on image\n",
        "              print(angle, \"|\", movement, \"|\", orientation)\n",
        "\n",
        "              plt.plot(*line_segment.xy, color='r', alpha=0.5)\n",
        "              room_polygons.plot(ax=ax, color='gray')\n",
        "\n",
        "              plt.plot(x1, y1, marker='o', color='green', markersize=2)  # plot the first point in green\n",
        "              plt.plot(x2_other, y2_other, 'bo', markersize=1)  # plot the other point in blue '''\n",
        "\n",
        "        #To check on image\n",
        "        #plt.show()\n",
        "      else:\n",
        "        print('no windows')\n",
        "    else:\n",
        "      print('skip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ImaCH79Kq7x"
      },
      "source": [
        "Window area\n",
        "\n",
        "---\n",
        "1. Make window_length numeric\n",
        "2. Calculate actual window height\n",
        "3. Calculate window area\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#1. Convert 'window_length' columns to numeric\n",
        "df_info['window_length'] = pd.to_numeric(df_info['window_length'], errors='coerce')\n",
        "\n",
        "\n",
        "#2. Calculate actual window height\n",
        "  # -> elevation of room - elevation of window = how much higher the window starts from floor\n",
        "  # -> height in window row - start  window = window_height\n",
        "\n",
        "# Filter rows where entity_subtype is not equal to 'WINDOW' and copy elevation vlaue of room to floor_height\n",
        "filtered_df = df_info[~df_info['entity_subtype'].isin(window_subtypes)][['apartment_id', 'area_id', 'elevation']]\n",
        "filtered_df = filtered_df.rename(columns={'elevation': 'floor_height'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh3yurPxCT5p"
      },
      "outputs": [],
      "source": [
        "# Merge filtered_df with df_info on apartment_id and area_id -> so all windows have correct floor_height of room\n",
        "df_info = df_info.merge(filtered_df, on=['apartment_id', 'area_id'], how='left')\n",
        "\n",
        "# Calculate window_height by subtracting elevation from floor_height for entity_subtype == 'WINDOW' and substracting this from window elevation\n",
        "df_info['window_height'] = df_info['height'] - (df_info['elevation'] - df_info['floor_height']).round(3)\n",
        "\n",
        "# Drop the floor_height column\n",
        "df_info.drop('floor_height', axis=1, inplace=True)\n",
        "\n",
        "#Remove the window_heights from the rows with rooms\n",
        "df_info.loc[~df_info['entity_subtype'].isin(window_subtypes), ['window_height']] = np.nan\n",
        "\n",
        "#3. Calculate the window area\n",
        "#Multiply windowheight with window length\n",
        "df_info['window_area'] = (df_info['height'] * df_info['window_length']).round(5)\n",
        "\n",
        "df_info.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_ieVuNzMyOP"
      },
      "source": [
        "Room total window area\n",
        "\n",
        "---\n",
        "1. Find sum of window_area per area_id\n",
        "2. Append window_area values to room rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Calculate the sum of window_area per room\n",
        "# Filter rows with entity_subtype = 'WINDOW' or 'OUTSIDE_DOOR'\n",
        "window_rows = df_info[df_info['entity_subtype'].isin(window_subtypes)]\n",
        "\n",
        "# Calculate sum of window_area for each room\n",
        "window_area_sum = window_rows.groupby(['apartment_id', 'area_id'])['window_area'].sum().round(3)\n",
        "\n",
        "# 2. Append window_area values to room rows\n",
        "# Update the 'window_area' column for rows with entity_subtype other than 'WINDOW' or 'OUTSIDE_DOOR' = rooms\n",
        "df_info.loc[~df_info['entity_subtype'].isin(window_subtypes), 'window_area'] = df_info.loc[~df_info['entity_subtype'].isin(window_subtypes)].apply(\n",
        "    lambda row: window_area_sum.get((row['apartment_id'], row['area_id']), np.nan), axis=1)\n",
        "\n",
        "df_info.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_XcWQKpNlmu"
      },
      "source": [
        "Nr. of window sides in room\n",
        "\n",
        "---\n",
        "1. Find number of unique window orientation per area_id\n",
        "2. Append to rows of rooms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Find number of unique window orientation per area_id\n",
        "# Group by apartment_id and area_id and get unique values of orientation and the number of orientation sides\n",
        "num_unique_orientations = df_info[df_info['entity_subtype'].isin(window_subtypes)].groupby(['apartment_id', 'area_id'])['orientation'].nunique()\n",
        "\n",
        "# 2. Append to rows of rooms\n",
        "# Assign number of unique orientations to nr_window_sides\n",
        "df_info.loc[~df_info['entity_subtype'].isin(window_subtypes), 'nr_window_sides'] = df_info.loc[~df_info['entity_subtype'].isin(window_subtypes)].apply(\n",
        "    lambda row: num_unique_orientations.get((row['apartment_id'], row['area_id']), np.nan), axis=1)\n",
        "\n",
        "# Change the NaN of the rooms without windows to zeros\n",
        "df_info[['nr_window_sides', 'window_length', 'window_area']] = df_info[['nr_window_sides', 'window_length', 'window_area']].fillna(0)\n",
        "\n",
        "# Convert 'nr_window_sides' columns to numeric\n",
        "df_info['nr_window_sides'] = pd.to_numeric(df_info['nr_window_sides'], errors='coerce')\n",
        "\n",
        "df_info.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89NYBEu9RKl2"
      },
      "source": [
        "Room orientation division\n",
        "\n",
        "---\n",
        "1. Find per room the total window_area sum per direction\n",
        "2. Calculate percentage of orientation\n",
        "3. For room combine orientation with correct percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Calculate the sum of orientation representation of window area per area_id\n",
        "# Filter rows with entity_subtype 'WINDOW' or 'OUTSIDE_DOOR' and group by area_id and orientation\n",
        "direction_sum = df_info[df_info['entity_subtype'].isin(window_subtypes)].groupby(['area_id', 'orientation'])['window_area'].sum()\n",
        "\n",
        "# Create a new column 'direction_sum' and assign the sum of window_area for each direction per area_id\n",
        "df_info['direction_sum'] = df_info.apply(lambda row: direction_sum.get((row['area_id'], row['orientation']), np.nan), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Calculate the percentage of window_area per orientation\n",
        "# Calculate the total window area per area_id\n",
        "total_window_area = df_info.loc[~df_info['entity_subtype'].isin(window_subtypes)].groupby('area_id')['window_area'].sum()\n",
        "\n",
        "# Calculate the percentage of direction distribution over total window area\n",
        "df_info['direction_percentage'] = df_info.apply(lambda row: round(row['direction_sum'] / total_window_area[row['area_id']] * 100, 1) if row['area_id'] and row['orientation'] else np.nan, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. For rooms, combine orientation with correct percentage\n",
        "room_orientations = {}\n",
        "\n",
        "# Iterate over the rows to aggregate unique orientation and direction_percentage combinations\n",
        "for _, row in df_info[df_info['entity_subtype'].isin(window_subtypes)].iterrows():\n",
        "    if pd.notnull(row['area_id']):\n",
        "        if row['area_id'] not in room_orientations:\n",
        "            room_orientations[row['area_id']] = set()\n",
        "        room_orientations[row['area_id']].add((row['orientation'], row['direction_percentage']))\n",
        "\n",
        "def get_orientation_percentage_comb(row):\n",
        "    if pd.notnull(row['area_id']) and row['entity_subtype'] not in ['WINDOW', 'OUTSIDE_DOOR']:\n",
        "        return list(room_orientations.get(row['area_id'], []))\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "# Create a new column 'orientation_percentage_comb' and assign the unique orientation and percentage combinations\n",
        "df_info['orientation_percentage'] = df_info.apply(get_orientation_percentage_comb, axis=1)\n",
        "\n",
        "# Convert the lists to NumPy arrays or empty arrays\n",
        "df_info['orientation_percentage'] = df_info['orientation_percentage'].apply(lambda x: np.array(x) if isinstance(x, list) else np.array([]))\n",
        "\n",
        "# Drop the direction_sum and direction_percentage columns\n",
        "df_info = df_info.drop(['direction_sum', 'direction_percentage'], axis=1)\n",
        "\n",
        "df_info.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGY8F2AyL-23"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "#To check if values are accesable for later analysis\n",
        "row_5 = df_info.loc[1015]\n",
        "orientation_percentage = row_5['orientation_percentage']\n",
        "print(orientation_percentage)  # Print the entire value\n",
        "print('')\n",
        "\n",
        "# Access the orientations and percentages separately\n",
        "orientations = orientation_percentage[:, 0]\n",
        "percentages = orientation_percentage[:, 1]\n",
        "\n",
        "print(orientations)  # Print the orientations\n",
        "print(percentages)  # Print the percentages\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op3ZdhlBS5qz"
      },
      "source": [
        "Room orientation\n",
        "\n",
        "---\n",
        "1. Find unique window orientation per area_id\n",
        "2. Append to rows of rooms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Find unique window orientation per area_id\n",
        "# Group by apartment_id and area_id and get unique values of orientation and the number of orientation sides\n",
        "unique_orientations = df_info[df_info['entity_subtype'].isin(window_subtypes)].groupby(['apartment_id', 'area_id'])['orientation'].unique()\n",
        "\n",
        "# 2. Append to rows of rooms\n",
        "# Assign unique orientations to 'orientation' for rows where entity_subtype != 'WINDOW'\n",
        "df_info['orientation'] = df_info.apply(lambda row: unique_orientations.get((row['apartment_id'], row['area_id']), np.nan) if row['entity_subtype'] not in ['WINDOW', 'OUTSIDE_DOOR'] else row['orientation'], axis=1)\n",
        "\n",
        "df_info.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixHqqiEeWS2W"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "#To check if values are accesable for later analysis\n",
        "row_X = df_info.loc[1015]\n",
        "orientations = row_X['orientation']\n",
        "print(orientations)  # Print the entire value\n",
        "print('')\n",
        "\n",
        "# Access the orientations and percentages separately\n",
        "for i in range(len(orientations)):\n",
        "  print(orientations[i])  # Print the percentages\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pil3Av9nTijS"
      },
      "source": [
        "Window to wall & room depth ratio\n",
        "\n",
        "---\n",
        "1. Converert area_id to describe outside, shared and wrong windows to numbers\n",
        "2. Get total wall length & room depth ratio from df_sim_info\n",
        "3. Calculate wall area\n",
        "4. Calculate window to wall ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_info['area_id'] = df_info['area_id'].replace('', np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Convert area_id to describe outside, shared and wrong windows to numbers\n",
        "# Replace 'SHARED' with 1, 'OUTSIDE' with 2, and 'WRONG' with 3 in the area_id column\n",
        "df_info['area_id'].replace(['SHARED', 'OUTSIDE', 'WRONG'], [1, 2, 3], inplace=True)\n",
        "\n",
        "# 2. Get total wall length & room depth ratio from df_sim_info\n",
        "# Merge layout_perimeter & room_depth_ratio into df_info based on apartment_id and area_id\n",
        "df_info = df_info.merge(df_sim_info[['apartment_id', 'area_id', 'room_depth_ratio', 'layout_perimeter', 'layout_area']], on=['apartment_id', 'area_id'], how='left')\n",
        "\n",
        "# 3. Calculate the wall area & drop layout_perimeter\n",
        "df_info['wall_area'] = (df_info['layout_perimeter'] * df_info['height']).round(3)\n",
        "\n",
        "# Remove the wall and depth values from the rows with windows and outside doors\n",
        "df_info.loc[df_info['entity_subtype'].isin(window_subtypes), ['wall_area', 'room_depth_ratio', 'orientation_percentage', 'layout_area']] = np.nan\n",
        "\n",
        "# 4. Calculate the window to wall ratio\n",
        "df_info['window_wall_ratio'] = (df_info['window_area'] / df_info['wall_area']).round(3)\n",
        "df_info['window_floor_ratio'] = (df_info['window_area'] / df_info['layout_area']).round(3)\n",
        "\n",
        "# Set the display format for floats to 3 decimal places\n",
        "pd.set_option('display.float_format', '{:.3f}'.format)\n",
        "\n",
        "df_info.tail(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "# use if you started half way!!!\n",
        "#If code does not work any more, continue from half dataframe\n",
        "path_half_doors = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/Swiss Dataset/SwissDataset_v3.0.0/InfoDataCSV_v2/SwissDataset_v3.0.0_info_{name}sites_halfdoors.csv'\n",
        "df_info_half_doors = pd.read_csv(path_half_doors, index_col=0)\n",
        "\n",
        "#Create (pandas) dataframe\n",
        "df_info_doors = pd.DataFrame(df_info_half_doors)\n",
        "df_info_doors.head() '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Bring back the information about doors again\n",
        "# Concatenate df_info and df_info_doors vertically\n",
        "df_info_results = pd.concat([df_info, df_info_doors], ignore_index=False)\n",
        "df_info_results.tail()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTyBs3SRKT9y"
      },
      "outputs": [],
      "source": [
        "## After the df is ready remove unnecessary columns\n",
        "df_info_results = df_info_results.drop(['layout_perimeter', 'height', 'outside_connection'], axis=1)\n",
        "\n",
        "df_info_results.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHOMGZ64o_jp"
      },
      "outputs": [],
      "source": [
        "# Save the DataFrame to an Excel CSV file\n",
        "path_final = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/Swiss Dataset/SwissDataset_v3.0.0/InfoDataCSV_v2/SwissDataset_v3.0.0_info_{name}sites.csv'\n",
        "df_info_results.to_csv(path_final, index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
