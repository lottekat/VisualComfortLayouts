{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFKav4aQOiuF"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCxH9kutODAE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from shapely.geometry import box\n",
        "from shapely.ops import transform , unary_union, cascaded_union, linemerge\n",
        "from shapely import affinity\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from matplotlib.patches import Wedge \n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "import random\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1mHhMXl0Ru_"
      },
      "source": [
        "## Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Create room info dataframe\n",
        "#Call CSV file of dataset, and import dataset using Pandas\n",
        "path_sim = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/Swiss Dataset/SwissDataset_v3.0.0/SwissDataset_v3.0.0_clean_v3_room.csv'\n",
        "Swiss_sim = pd.read_csv(path_sim)\n",
        "\n",
        "#Create (pandas) dataframe\n",
        "df_sim = pd.DataFrame(Swiss_sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Create room info dataframe\n",
        "#Call CSV file of dataset, and import dataset using Pandas\n",
        "path_info = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/Swiss Dataset/SwissDataset_v3.0.0/SwissDataset_v3.0.0_clean_v3_info.csv'\n",
        "Swiss_info = pd.read_csv(path_info)\n",
        "\n",
        "#Create (pandas) dataframe\n",
        "df_info = pd.DataFrame(Swiss_info)\n",
        "df_res = df_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Create room info dataframe\n",
        "#Call CSV file of dataset, and import dataset using Pandas\n",
        "path_geom = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/Swiss Dataset/SwissDataset_v3.0.0/SwissDataset_v3.0.0_geometries.csv'\n",
        "Swiss_geom = pd.read_csv(path_geom)\n",
        "\n",
        "#Create (pandas) dataframe\n",
        "df_geom = pd.DataFrame(Swiss_geom)\n",
        "\n",
        "#Filter out features\n",
        "df_geom = df_geom[df_geom[\"entity_type\"] != \"feature\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ymgaTh50GpV"
      },
      "source": [
        "1st round of cleaning dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_dataframe(df):\n",
        "    # Reduce the number of variables in entity_subtype, separators\n",
        "    df.loc[df['entity_subtype'] == 'COLUMN', 'entity_subtype'] = 'WALL'\n",
        "    df.loc[df['entity_subtype'] == 'ENTRANCE_DOOR', 'entity_subtype'] = 'DOOR'\n",
        "\n",
        "    # Put all the outdoor spaces under one name\n",
        "    categories_to_outdoor = ['BALCONY', 'LOGGIA', 'TERRACE', 'WINTERGARTEN', 'PATIO', 'GARDEN', 'RAILING']\n",
        "    for category in categories_to_outdoor:\n",
        "        df.loc[df['entity_subtype'] == category, 'entity_subtype'] = 'OUTDOOR_SPACE'\n",
        "    df.loc[df['entity_subtype'] == 'RAILING', 'entity_subtype'] = 'OUTDOOR_SPACE'\n",
        "\n",
        "    # Put all the living space functions under one name\n",
        "    categories_to_living = ['LIVING_DINING', 'DINING', 'KITCHEN_DINING']\n",
        "    for category in categories_to_living:\n",
        "        df.loc[df['entity_subtype'] == category, 'entity_subtype'] = 'DINING'\n",
        "\n",
        "    # Reduce the number of variables in entity_subtype, separators\n",
        "    df.loc[df['entity_subtype'] == 'COLUMN', 'entity_subtype'] = 'WALL'\n",
        "    df.loc[df['entity_subtype'] == 'ENTRANCE_DOOR', 'entity_subtype'] = 'DOOR'\n",
        "\n",
        "    # Put all the other functions under one name\n",
        "    categories_to_other = ['SHAFT', 'NOT_DEFINED']\n",
        "    for category in categories_to_other:\n",
        "        df.loc[df['entity_subtype'] == category, 'entity_subtype'] = 'OTHER'\n",
        "\n",
        "    # Put all the void functions under one name\n",
        "    categories_to_void = ['OUTDOOR_VOID', 'LIGHTWELL', 'VOID']\n",
        "    for category in categories_to_void:\n",
        "        df.loc[df['entity_subtype'] == category, 'entity_subtype'] = 'VOID'\n",
        "\n",
        "    # Put all the circulation functions under one name\n",
        "    categories_to_circulation = ['ELEVATOR', 'CORRIDORS_AND_HALLS', 'ELEVATOR_FACILITIES', 'STAIRCASE']\n",
        "    for category in categories_to_circulation:\n",
        "        df.loc[df['entity_subtype'] == category, 'entity_subtype'] = 'CIRCULATION'\n",
        "\n",
        "    # Put all the public functions under one name\n",
        "    categories_to_public = ['BASEMENT_COMPARTMENT', 'OFFICE', 'PRAM', 'PRAM_AND_BIKE_STORAGE_ROOM', \n",
        "                            'BIKE_STORAGE', 'COUNTER_ROOM', 'BASEMENT', 'TECHNICAL_AREA', 'HEATING',  'WASH_AND_DRY_ROOM',\n",
        "                            'CLOAKROOM', 'SALESROOM', 'GARAGE', 'OIL_TANK', 'HOUSE_TECHNICS_FACILITIES', 'OFFICE_SPACE',\n",
        "                            'OFFICE_TECH_ROOM', 'WAREHOUSE', 'CARPARK', 'SANITARY_ROOMS', 'OPEN_PLAN_OFFICE', 'MEETING_ROOM',\n",
        "                            'BREAK_ROOM', 'ARCHIVE', 'ELECTRICAL_SUPPLY', 'MEDICAL_ROOM', 'WAITING_ROOM', 'COMMON_KITCHEN',\n",
        "                            'VEHICLE_TRAFFIC_AREA', 'AIR', 'FACTORY_ROOM', 'RECEPTION_ROOM', 'COMMUNITY_ROOM', 'WORKSHOP',\n",
        "                            'CANTEEN', 'SHELTER', 'COLD_STORAGE', 'TRANSPORT_SHAFT', 'RADATION_THERAPY', 'PHYSIO_AND_REHABILITATION',\n",
        "                            'WATER_SUPPLY', 'DEDICATED_MEDICAL_ROOM', 'SPORTS_ROOMS', 'SHOWROOM', 'GAS', 'TEACHING_ROOM', 'ARCADE',\n",
        "                            'LOGISTICS', 'OPERATIONS_FACILITIES', 'LOBBY', 'FOYER']\n",
        "    for category in categories_to_public:\n",
        "        df.loc[df['entity_subtype'] == category, 'entity_subtype'] = 'PUBLIC'\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_geom = process_dataframe(df_geom)\n",
        "print(df_geom['entity_subtype'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_geom.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k5cJeXRGkgK"
      },
      "outputs": [],
      "source": [
        "df_res = process_dataframe(df_res)\n",
        "\n",
        "subtypes_to_exclude = ['OTHER', 'VOID', 'OUTDOOR_SPACE']\n",
        "df_res = df_res[~df_res['entity_subtype'].isin(subtypes_to_exclude)]\n",
        "\n",
        "print(df_res['entity_subtype'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sim = process_dataframe(df_sim)\n",
        "\n",
        "subtypes_to_exclude = ['OTHER', 'VOID', 'OUTDOOR_SPACE']\n",
        "df_sim = df_sim[~df_sim['entity_subtype'].isin(subtypes_to_exclude)]\n",
        "\n",
        "print(df_sim['entity_subtype'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpYm-aOs0Pbf"
      },
      "source": [
        "Create color code & sort dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMqHZDoKPBTs"
      },
      "outputs": [],
      "source": [
        "# Define the desired sort order as a list with corresponding colours\n",
        "# Create a dictionary to map categories to their corresponding colors\n",
        "category_to_color = {'ROOM':            '#F7D08A',  # sunset / light yellow\n",
        "                     'WALL':            '#F6F5F4',  # smoke white\n",
        "                     'DOOR':            '#E5DEDC',  #timerwolf\n",
        "                     'OUTSIDE_DOOR':    '#94BDAA',  #cambridge blue\n",
        "                     'WINDOW':          '#B5E3F1',  #light blue\n",
        "                    }\n",
        "\n",
        "# Extract the categories from the data and map them to their corresponding colors\n",
        "categories = list(category_to_color.keys())\n",
        "colors = [category_to_color[category] for category in categories]\n",
        "\n",
        "# Create a color map from the used colors\n",
        "color_map = ListedColormap(colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afEMtKs4AMbG"
      },
      "outputs": [],
      "source": [
        "# Define the desired sort order as a list with corresponding colours\n",
        "# Create a dictionary to map categories to their corresponding colors\n",
        "category_to_color1 = {'BALCONY':     'whitesmoke',\n",
        "                      'LOGGIA':     'whitesmoke',\n",
        "                      'WALL':        'grey',\n",
        "                      'DOOR':        'lightgrey',\n",
        "                      'WINDOW':      'lightgrey'}\n",
        "\n",
        "# Extract the categories from the data and map them to their corresponding colors\n",
        "categories1 = list(category_to_color1.keys())\n",
        "colors_grey = [category_to_color1[category] for category in categories1]\n",
        "\n",
        "# Create a color map from the used colors\n",
        "color_map_daylight = ListedColormap(colors_grey)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keyusEtO06xw"
      },
      "source": [
        "2nd round of cleaning datafream\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Create 2 dataframes, one with only residential types, and one with also the\n",
        "public functions present\n",
        "And change dataframes to Geopandas dataframe with usable geometry column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA6oOXsR7Jtp"
      },
      "outputs": [],
      "source": [
        "#Create geoseries with polygons -> change wkt to polygon\n",
        "# Check if the 'geometry' column is already a GeoSeries object\n",
        "if df_res['geometry'].dtype == 'geometry':\n",
        "  gs_res = df_res['geometry']\n",
        "  gs_geom = df_geom['geometry']\n",
        "else:\n",
        "  gs_res = gpd.GeoSeries.from_wkt(df_res['geometry'])\n",
        "  gs_geom = gpd.GeoSeries.from_wkt(df_geom['geometry'])\n",
        "\n",
        "#Create new Geodataframes with polygons\n",
        "gdf_res = gpd.GeoDataFrame(df_res, geometry=gs_res, crs=None)\n",
        "gdf_geom = gpd.GeoDataFrame(df_geom, geometry=gs_geom, crs=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5iZlNnTy98h"
      },
      "source": [
        "#Create dataframe - simulation results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sim.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDyjgxiN6hpn"
      },
      "source": [
        "Create dataframe with view results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z8271toDAiBZ",
        "outputId": "8b7e1ce7-d765-474d-d1a5-ee985f0e778f"
      },
      "outputs": [],
      "source": [
        "# Select only desired columns for view dataframe\n",
        "df_view = df_sim.loc[:, ['area_id', 'apartment_id', 'entity_subtype', 'view_site_mean',\n",
        "                         'view_ground_mean', 'view_landscape_nature_mean', 'view_landscape_urban_mean', 'view_sky_mean']]\n",
        "\n",
        "df_view.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv9kQeRz2wg8"
      },
      "source": [
        "Get the min and max values out of the simulation data, so the greyscales can be adjusted to this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "V1cc7Sc_xyno",
        "outputId": "fd2524b8-6c15-4f4a-822b-cd2bf63a7686"
      },
      "outputs": [],
      "source": [
        "# Get the min and max values of each column\n",
        "view_cols = ['view_site_mean', 'view_ground_mean', 'view_landscape_nature_mean', 'view_landscape_urban_mean', 'view_sky_mean']\n",
        "min_max_list = [(col, df_view[col].min(), df_view[col].max()) for col in view_cols]\n",
        "\n",
        "# Create a new dataframe with column name, min, and max\n",
        "min_max_df_view = pd.DataFrame(min_max_list, columns=['column_name', 'min', 'max'])\n",
        "# Round 'min' and 'max' columns to one decimal place\n",
        "min_max_df_view['min'] = min_max_df_view['min'].round(1)\n",
        "min_max_df_view['max'] = min_max_df_view['max'].round(1)\n",
        "\n",
        "min_max_df_view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "O4LzaG9J1ctI",
        "outputId": "0fe7dd5a-1f21-45e4-a20a-70e93af1b9e5"
      },
      "outputs": [],
      "source": [
        "df_daylight = df_sim.loc[:, ['area_id', 'apartment_id', 'entity_subtype', 'daylight_21Mar1200_median', 'daylight_21Jun1200_median', 'daylight_21Dec1200_median']]\n",
        "df_daylight.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the min and max values of each column\n",
        "daylight_cols = ['daylight_21Mar1200_median', 'daylight_21Jun1200_median', 'daylight_21Dec1200_median']\n",
        "min_max_list = [(col, df_daylight[col].min(), df_daylight[col].max()) for col in daylight_cols]\n",
        "\n",
        "# Create a new dataframe with column name, min, and max\n",
        "min_max_df_daylight = pd.DataFrame(min_max_list, columns=['column_name', 'min', 'max'])\n",
        "\n",
        "min_max_df_daylight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6NMmeJV5DOj"
      },
      "source": [
        "#Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAaWjP5JbTmD"
      },
      "outputs": [],
      "source": [
        "def room_info(gdf_res, area_id):\n",
        "  #locate the specific apartement in the dataframe\n",
        "  gdf_room = gdf_res.loc[gdf_res[\"area_id\"]== area_id]\n",
        "\n",
        "  app_id = gdf_room['apartment_id']\n",
        "\n",
        "  #Find the corresponding site, building, floor and unit id\n",
        "  room_code_columns = ['site_id', 'building_id', 'floor_id', 'unit_id']\n",
        "  room_code = [int(val) for col in room_code_columns for val in gdf_room[col].unique()]\n",
        "  room_code_values = room_code + [app_id]\n",
        "\n",
        "  #Create one string for the apartment code\n",
        "  room_code_str = '-'.join(str(e) for e in room_code_values)\n",
        "\n",
        "  #Add in the app_id to have all the info in one place\n",
        "  room_code.append(app_id)\n",
        "\n",
        "  return gdf_room, room_code, room_code_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def floor_info(gdf_geom, app_id):\n",
        "    # Create gdf_floor by filtering gdf_geom\n",
        "    app_data = gdf_geom[gdf_geom['apartment_id'] == app_id].iloc[0]\n",
        "    floor_id = app_data['floor_id']\n",
        "    building_id = app_data['building_id']\n",
        "    elevation_id = app_data['elevation']\n",
        "\n",
        "    #generate dataframes with floor geometry\n",
        "    gdf_floor = gdf_geom[gdf_geom['floor_id'] == floor_id].copy()\n",
        "    gdf_outdoor_space = gdf_floor[gdf_floor['entity_subtype'] == 'OUTDOOR_SPACE']\n",
        "\n",
        "\n",
        "    #Find the higher floors, first find the corresponding building \n",
        "    gdf_building_area = gdf_geom[(gdf_geom['building_id'] == building_id) & (gdf_geom['entity_type'] == 'area')].copy()\n",
        "\n",
        "    # Get unique elevation values from the filtered DataFrame and sort them\n",
        "    building_elevations_sorted = sorted(gdf_building_area['elevation'].unique())\n",
        "\n",
        "    # Initialize lists to store elevation values and corresponding floor IDs\n",
        "    higher_elevations = []\n",
        "    higher_floor_ids = []\n",
        "\n",
        "    # Check if the current elevation is not the highest value\n",
        "    if elevation_id < max(building_elevations_sorted):\n",
        "        # Iterate through the sorted unique elevations list\n",
        "        for elevation in building_elevations_sorted:\n",
        "            # Check if the elevation is higher than the current elevation\n",
        "            if elevation > elevation_id:\n",
        "                # Found a higher elevation\n",
        "                higher_elevations.append(elevation)\n",
        "        \n",
        "        # Find the floor IDs of the floors above the current floor\n",
        "        higher_floor_ids = gdf_building_area.loc[gdf_building_area['elevation'].isin(higher_elevations), 'floor_id'].tolist()\n",
        "\n",
        "    #generate dataframes with floor geometry\n",
        "    gdf_higher_floors = gdf_geom[gdf_geom['floor_id'].isin(higher_floor_ids)].copy()\n",
        "    gdf_overhang = pd.DataFrame()\n",
        "\n",
        "    if not gdf_higher_floors.empty:\n",
        "        #create a buffer to exclude small imperfections in geometry\n",
        "        gdf_floor_buffered = gdf_floor.copy()\n",
        "        gdf_floor_buffered['geometry'] = gdf_floor['geometry'].buffer(0.01)\n",
        "\n",
        "        #Find the difference between the current floor and the floors above\n",
        "        gdf_overhang = gpd.overlay(gdf_higher_floors, gdf_floor_buffered, how='difference')\n",
        "\n",
        "    return gdf_floor, gdf_outdoor_space, gdf_overhang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bbox_rect(gdf_room):\n",
        "  #Create a dataframe with only rooms and create a small buffer for geometry\n",
        "  gdf_room_area = gdf_room[gdf_room['entity_subtype'] == 'ROOM']\n",
        "\n",
        "  #Take the unary union of the buffered polygons and create the minimum rotated rectangle\n",
        "  poly_rooms = gdf_room_area[\"geometry\"].unary_union\n",
        "  gdf_poly_rooms = gpd.GeoDataFrame(geometry=[poly_rooms])\n",
        "  rect_rooms = poly_rooms.minimum_rotated_rectangle\n",
        "\n",
        "  #Calculate the current dimensions of the rectangle in meters\n",
        "  x_info, y_info = rect_rooms.exterior.xy\n",
        "  x_distance = max(x_info) - min(x_info)\n",
        "  y_distance = max(y_info) - min(y_info)\n",
        "\n",
        "  #Scale the rectangle tothe specified unit size = 15x15\n",
        "  xfact = 15 / x_distance\n",
        "  yfact = 15 / y_distance\n",
        "  rect_rooms_buffered = affinity.scale(rect_rooms, xfact=xfact, yfact=yfact)\n",
        "\n",
        "  #Create a bounding box around the rect_rooms_buffered with size 15x15\n",
        "  rect = box(*rect_rooms_buffered.bounds)\n",
        "  gdf_rect = gpd.GeoDataFrame(geometry=[rect])\n",
        "\n",
        "  # Calculate the environmental circles\n",
        "  rect_centroid = rect.centroid\n",
        "  img_centre = (rect_centroid.x, rect_centroid.y)\n",
        "\n",
        "  return gdf_rect, img_centre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWOx83gM0aBG"
      },
      "source": [
        "# Visualization Swiss dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG_9PNFwQiDd"
      },
      "outputs": [],
      "source": [
        "# Set the path to the directory where you want to save the plot\n",
        "path_png = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/10_Images_04Dataset_layouts/05_Room_Feature_v5_png'\n",
        "path_npy_pred = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/10_Images_04Dataset_layouts/05_Room_Feature_v5.pred_npy'\n",
        "path_npy0 = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/10_Images_04Dataset_layouts/05_Room_Feature_v5.0_npy'\n",
        "path_npy1 = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/10_Images_04Dataset_layouts/05_Room_Feature_v5.1_npy'\n",
        "path_npy2 = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/10_Images_04Dataset_layouts/05_Room_Feature_v5.2_npy'\n",
        "path_npy3 = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/10_Images_04Dataset_layouts/05_Room_Feature_v5.3_npy'\n",
        "path_npy4 = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/10_Images_04Dataset_layouts/05_Room_Feature_v5.4_npy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "sites_pred = [386, 1067, 1105, 11726, 3641, 3958, 11756, 2291, 401, 194, 277, 66, 2161, 789]\n",
        "gdf_res_pred = gdf_res.loc[gdf_res['site_id'].isin(sites_pred)]\n",
        "unique_app_ids_pred = gdf_res_pred['apartment_id'].unique()'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#exclude the already plotted apartments so the loop does not include those again \n",
        "# Use list comprehension to get a list of all image file names in the directory\n",
        "image_file_names0 = [f for f in os.listdir(path_npy0) if f.endswith('.npy')]\n",
        "image_file_names1 = [f for f in os.listdir(path_npy1) if f.endswith('.npy')]\n",
        "image_file_names2 = [f for f in os.listdir(path_npy2) if f.endswith('.npy')]\n",
        "image_file_names3 = [f for f in os.listdir(path_npy3) if f.endswith('.npy')]\n",
        "image_file_names4 = [f for f in os.listdir(path_npy4) if f.endswith('.npy')]\n",
        "image_file_names_pred = [f for f in os.listdir(path_npy_pred) if f.endswith('.npy')]\n",
        "\n",
        "combined_image_file_names_training = image_file_names0 + image_file_names1 + image_file_names2 + image_file_names3 + image_file_names4\n",
        "combined_image_file_names = combined_image_file_names_training + image_file_names_pred\n",
        "\n",
        "# Extract apartment IDs\n",
        "plotted_apartment_ids = [file_name.split('_')[0] for file_name in combined_image_file_names]\n",
        "plotted_area_ids = [int(file_name.split('_')[1].split('.')[0]) for file_name in combined_image_file_names]\n",
        "pred_apartment_ids = [file_name.split('_')[0] for file_name in image_file_names_pred]\n",
        "train_apartment_ids = [apartment_id for apartment_id in plotted_apartment_ids if apartment_id not in pred_apartment_ids]\n",
        "\n",
        "# Get unique apartment IDs and area IDs\n",
        "unique_plotted_apartment_ids = list(set(plotted_apartment_ids))\n",
        "unique_pred_apartment_ids = list(set(pred_apartment_ids))\n",
        "unique_train_apartment_ids = list(set(train_apartment_ids))\n",
        "\n",
        "print(f'training: app={len(unique_train_apartment_ids)}, rooms={len(combined_image_file_names_training)}')\n",
        "print(f'prediction: app={len(unique_pred_apartment_ids)}, rooms={len(image_file_names_pred)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_total = df_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tot_site = df_sim['site_id'].nunique()\n",
        "tot_building = df_sim['building_id'].nunique()\n",
        "tot_app = df_sim['apartment_id'].nunique()\n",
        "tot_rooms = df_sim.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = df_sim.loc[df_sim['apartment_id'].isin(unique_train_apartment_ids)]\n",
        "train_site = df_train['site_id'].nunique()\n",
        "train_building = df_train['building_id'].nunique()\n",
        "train_app = df_train['apartment_id'].nunique()\n",
        "train_rooms = len(combined_image_file_names_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pred = df_sim.loc[df_sim['apartment_id'].isin(unique_pred_apartment_ids)]\n",
        "pred_site = df_pred['site_id'].nunique()\n",
        "pred_building = df_pred['building_id'].nunique()\n",
        "pred_app = df_pred['apartment_id'].nunique()\n",
        "pred_rooms = len(image_file_names_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a dictionary with your data\n",
        "data_overview = {   'Category': ['Sites', 'Buildings', 'Apartments', 'Rooms'],\n",
        "                    'Total _overviewset': [tot_site, tot_building, tot_app, tot_rooms],  \n",
        "                    'Training Dataset': [train_site, train_building, train_app, train_rooms],  \n",
        "                    'Prediction Dataset': [pred_site, pred_building, pred_app, pred_rooms]\n",
        "}\n",
        "\n",
        "# Convert the dictionary into a Pandas DataFrame\n",
        "df_dataset_overview = pd.DataFrame(data_overview)\n",
        "print(df_dataset_overview)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_to_plot = df_sim.loc[~df_sim['apartment_id'].isin(unique_plotted_apartment_ids)]\n",
        "toplot_site = df_to_plot['site_id'].nunique()\n",
        "toplot_building = df_to_plot['building_id'].nunique()\n",
        "toplot_app = df_to_plot['apartment_id'].nunique()\n",
        "\n",
        "print(f'to plot: sites={toplot_site}, buildings={toplot_building}, apps={toplot_app}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_elevation = df_sim['elevation'].max()\n",
        "min_elevation = df_sim['elevation'].min()\n",
        "print(f'elevation: min={min_elevation}, max={max_elevation}')\n",
        "\n",
        "max_windowfloor = df_sim['window_floor_ratio'].max()\n",
        "min_windowfloor = df_sim['window_floor_ratio'].min()\n",
        "print(f'window to floor ratio: min={min_windowfloor}, max={max_windowfloor}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_view_sky = df_sim['view_sky_p80'].max()\n",
        "print(f'max view sky: {max_view_sky}')\n",
        "max_view_ground = df_sim['view_ground_p80'].max()\n",
        "print(f'max view ground: {max_view_ground}')\n",
        "\n",
        "max_daylight_Mar = df_sim['daylight_21Mar1200_median'].max()\n",
        "print(f'max daylight Mar: {max_daylight_Mar}')\n",
        "max_daylight_Jun = df_sim['daylight_21Jun1200_median'].max()\n",
        "print(f'max daylight Jun: {max_daylight_Jun}')\n",
        "max_daylight_Dec = df_sim['daylight_21Dec1200_median'].max()\n",
        "print(f'max daylight Dec: {max_daylight_Dec}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the normalized elevation column\n",
        "df_total['elevation_normalized'] = (df_total['elevation'] - min_elevation) / (max_elevation - min_elevation)\n",
        "\n",
        "# Calculate the values for the new column and replace NaN with 0\n",
        "df_total['window_floor_ratio_normalized'] = df_total['window_floor_ratio'] / max_windowfloor\n",
        "df_total['window_floor_ratio_normalized'].fillna(0, inplace=True)\n",
        "\n",
        "# Normalise the dalight and sky view values\n",
        "df_total['view_sky_p80_normalized'] = df_total['view_sky_p80'] / max_view_sky\n",
        "df_total['view_ground_p80_normalized'] = df_total['view_ground_p80'] / max_view_ground\n",
        "df_total['daylight_21Mar1200_median_normalized'] = df_total['daylight_21Mar1200_median'] / max_daylight_Mar\n",
        "df_total['daylight_21Jun1200_median_normalized'] = df_total['daylight_21Jun1200_median'] / max_daylight_Jun\n",
        "df_total['daylight_21Dec1200_median_normalized'] = df_total['daylight_21Dec1200_median'] / max_daylight_Dec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the normalized elevation column\n",
        "df_train['elevation_normalized'] = (df_train['elevation'] - min_elevation) / (max_elevation - min_elevation)\n",
        "\n",
        "# Calculate the values for the new column and replace NaN with 0\n",
        "df_train['window_floor_ratio_normalized'] = df_train['window_floor_ratio'] / max_windowfloor\n",
        "df_train['window_floor_ratio_normalized'].fillna(0, inplace=True)\n",
        "\n",
        "# Normalise the dalight and sky view values\n",
        "df_train['view_sky_p80_normalized'] = df_train['view_sky_p80'] / max_view_sky\n",
        "df_train['view_ground_p80_normalized'] = df_train['view_ground_p80'] / max_view_ground\n",
        "df_train['daylight_21Mar1200_median_normalized'] = df_train['daylight_21Mar1200_median'] / max_daylight_Mar\n",
        "df_train['daylight_21Jun1200_median_normalized'] = df_train['daylight_21Jun1200_median'] / max_daylight_Jun\n",
        "df_train['daylight_21Dec1200_median_normalized'] = df_train['daylight_21Dec1200_median'] / max_daylight_Dec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the normalized elevation column\n",
        "df_pred['elevation_normalized'] = (df_pred['elevation'] - min_elevation) / (max_elevation - min_elevation)\n",
        "\n",
        "# Calculate the values for the new column and replace NaN with 0\n",
        "df_pred['window_floor_ratio_normalized'] = df_pred['window_floor_ratio'] / max_windowfloor\n",
        "df_pred['window_floor_ratio_normalized'].fillna(0, inplace=True)\n",
        "\n",
        "# Normalise the dalight and sky view values\n",
        "df_pred['view_sky_p80_normalized'] = df_pred['view_sky_p80'] / max_view_sky\n",
        "df_pred['view_ground_p80_normalized'] = df_pred['view_ground_p80'] / max_view_ground\n",
        "df_pred['daylight_21Mar1200_median_normalized'] = df_pred['daylight_21Mar1200_median'] / max_daylight_Mar\n",
        "df_pred['daylight_21Jun1200_median_normalized'] = df_pred['daylight_21Jun1200_median'] / max_daylight_Jun\n",
        "df_pred['daylight_21Dec1200_median_normalized'] = df_pred['daylight_21Dec1200_median'] / max_daylight_Dec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a figure and axis for the boxplots\n",
        "fig, ax = plt.subplots(figsize=(18, 11))\n",
        "\n",
        "# Define properties for the fliers (outliers)\n",
        "flierprops = dict(marker='o', markerfacecolor='#808081', markersize=3, alpha=0.2)\n",
        "\n",
        "# Set the positions for the boxplots\n",
        "positions = [0.15, 0.90, 1.80, 2.55, 3.3, 4.2, 4.95]\n",
        "\n",
        "# Define dataframes and colors\n",
        "dataframes = [df_pred, df_train, df_total]\n",
        "colors = ['#F7D08A', '#B0647E', '#084C61']\n",
        "\n",
        "# Define labels\n",
        "labels = ['Ground view\\np80', 'Sky view\\np80', 'Daylight 21 Dec\\n12:00 median', 'Daylight 21 Jun\\n12:00 median',\n",
        "          'Daylight 21 Mar\\n12:00 median', 'Window to\\nFloor Ratio', 'Elevation']\n",
        "\n",
        "# Loop through the data and create boxplots\n",
        "for i, feature in enumerate(['view_ground_p80_normalized', 'view_sky_p80_normalized',\n",
        "                            'daylight_21Dec1200_median_normalized', 'daylight_21Jun1200_median_normalized',\n",
        "                            'daylight_21Mar1200_median_normalized', 'window_floor_ratio_normalized', 'elevation_normalized']):\n",
        "    for j, df in enumerate(dataframes):\n",
        "        ax.boxplot(df[feature], positions=[positions[(i)] + j * 0.2], patch_artist=True, vert=False, widths=0.15,\n",
        "                   flierprops=flierprops, medianprops={'color': 'black'})\n",
        "        for boxplot in ax.boxplot(df[feature], positions=[positions[i] + j*0.2], patch_artist=True, vert=False, widths=0.15,\n",
        "                                  flierprops=flierprops, medianprops={'color': 'black'})['boxes']:\n",
        "            boxplot.set(facecolor=colors[j])\n",
        "\n",
        "# Set titles for the boxplots\n",
        "ax.set_title('Distribution feature & label values over datasets')\n",
        "positions_labels = [0.35, 1.1, 2.0, 2.75, 3.5, 4.4, 5.15]\n",
        "ax.set_yticks(positions_labels)\n",
        "ax.set_yticklabels(labels)\n",
        "ax.set_xlim(-0.01, 1.01)\n",
        "ax.set_ylim(0,5.5)\n",
        "ax.set_xlabel('Normalised values')\n",
        "\n",
        "# Create custom legend\n",
        "legend_handles = []\n",
        "dataset_tags = ['Total', 'Training', 'Prediction']\n",
        "colors_tags = ['#084C61', '#B0647E', '#F7D08A']\n",
        "\n",
        "for i, dataset in enumerate(dataset_tags):\n",
        "    legend_handles.append(mpatches.Patch(color=colors_tags[i], label=dataset))\n",
        "plt.legend(handles=legend_handles, loc='upper right', bbox_to_anchor=(1, 1.05), fontsize='small', ncol=3)\n",
        "\n",
        "# Show the plot\n",
        "boxplot_path = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/10_Images_04Dataset_data/Boxplots_v4/'\n",
        "plt.savefig(f'{boxplot_path}boxplot_dataset_featurelabel_distribution.png', bbox_inches='tight', dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "plotted_buildings = df_train['building_id'].unique()\n",
        "toplot_buildings = df_to_plot['building_id'].unique()\n",
        "\n",
        "# Find building_ids that are in toplot_buildings but not in plotted_buildings\n",
        "building_ids_not_plotted = set(toplot_buildings) - set(plotted_buildings)\n",
        "\n",
        "# If you want the result as a list, you can convert the set back to a list\n",
        "building_ids_not_plotted_list = list(building_ids_not_plotted)\n",
        "df_filtered_to_plot = df_to_plot[df_to_plot['building_id'].isin(building_ids_not_plotted_list)]\n",
        "# Print the result\n",
        "print(building_ids_not_plotted_list)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "plotted_sites = df_train['site_id'].unique()\n",
        "toplot_sites = df_to_plot['site_id'].unique()\n",
        "\n",
        "# Find site_ids that are in toplot_sites but not in plotted_sites\n",
        "site_ids_not_plotted = set(toplot_sites) - set(plotted_sites)\n",
        "\n",
        "# If you want the result as a list, you can convert the set back to a list\n",
        "site_ids_not_plotted_list = list(site_ids_not_plotted)\n",
        "df_filtered_to_plot = df_to_plot[df_to_plot['site_id'].isin(site_ids_not_plotted_list)]\n",
        "# Print the result\n",
        "print(site_ids_not_plotted_list)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_sites = [1067, 735, 983, 66, 1105, 3958, 1026, 194, 2133, 2291, 401, 1024,\n",
        "                386, 11726, 277, 11749, 11756, 789, 2161, 3641]\n",
        "\n",
        "#df_filtered_to_plot = df_to_plot[df_to_plot['site_id'].isin(pred_sites)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exclude values in unique_plotted_apartment_ids from unique_app_ids\n",
        "to_plot_app_ids = df_to_plot['apartment_id'].unique()\n",
        "to_plot_app_ids = list(to_plot_app_ids)\n",
        "print(len(to_plot_app_ids))\n",
        "\n",
        "# Randomly select apartment IDs from to_plot_app_ids\n",
        "random_selected_apartment_ids = random.sample(to_plot_app_ids, 17)\n",
        "\n",
        "# run loop to generate room images\n",
        "for app_id in random_selected_apartment_ids:\n",
        "#for app_id in app_ids:\n",
        "  #Get dataframe of apartment in which room lies\n",
        "  gdf_apartment = gdf_res.loc[gdf_res[\"apartment_id\"]== app_id]\n",
        "  gdf_apartment_doors = gdf_res.loc[(gdf_res[\"apartment_id\"] == app_id) & (gdf_res[\"entity_subtype\"] == 'DOOR')]\n",
        "  #print(app_id)\n",
        "\n",
        "  #find current and next floor_id\n",
        "  gdf_floor, gdf_outdoor_space, gdf_overhang = floor_info(gdf_geom, app_id)\n",
        "  \n",
        "  # Check if there is any geometry in the 'difference' result\n",
        "  if not gdf_overhang.empty:\n",
        "    gdf_overhang_buffered = gdf_overhang.copy()\n",
        "    gdf_overhang_buffered['geometry'] = gdf_overhang['geometry'].buffer(0.01)\n",
        "    union_overhang = gdf_overhang_buffered.unary_union\n",
        "\n",
        "  #for area_id in apartment:\n",
        "  for area_id in gdf_apartment['area_id'].unique():\n",
        "    #locate the specific apartement in the dataframe\n",
        "    gdf_room = gdf_apartment.loc[gdf_apartment[\"area_id\"]== area_id]\n",
        "  \n",
        "    # check if the dataframe is not empty\n",
        "    if not gdf_room.empty:\n",
        "      #Generate the full room geometry\n",
        "      # Check if 'door_connection1' or 'door_connection2' is equal to area_id\n",
        "      mask = (gdf_apartment_doors['door_connection1'] == area_id) | (gdf_apartment_doors['door_connection2'] == area_id)\n",
        "\n",
        "      # Add the matching rows to gdf_room_doors\n",
        "      gdf_room_doors = gdf_apartment_doors[mask]\n",
        "      gdf_room = pd.concat([gdf_room, gdf_room_doors], ignore_index=False)\n",
        "      \n",
        "      # Update 'entity_subtype' to 'ROOM' when it's not equal to 'window', 'door', or 'outside_door'\n",
        "      gdf_room.loc[~gdf_room['entity_subtype'].isin(['WINDOW', 'DOOR', 'OUTSIDE_DOOR']), 'entity_subtype'] = 'ROOM'\n",
        "\n",
        "      #find properties about view simulations of room\n",
        "      df_sim_room = df_sim.loc[(df_sim[\"area_id\"] == area_id) & (df_sim[\"apartment_id\"] == app_id)]\n",
        "      if not df_sim_room.empty:\n",
        "        # Set the figure size in inches to match the desired pixel size (224x224)\n",
        "        fig, ax = plt.subplots(figsize=(10, 10), dpi=100)\n",
        "\n",
        "        #Plot the above floors\n",
        "        if not gdf_overhang.empty:\n",
        "          gpd.GeoSeries([union_overhang]).plot(ax=ax, color='#E0DFDE')\n",
        "\n",
        "        #plot the floor of the apartment\n",
        "        gdf_floor.plot(ax=ax, color='#F6F5F4')\n",
        "        \n",
        "        #plot the outdoor spaces\n",
        "        if not gdf_outdoor_space.empty:\n",
        "          gdf_outdoor_space.plot(ax=ax, color='#ECEAE9')\n",
        "        \n",
        "        #plot the room geomerty \n",
        "        gdf_room.plot(column=\"entity_subtype\", cmap=color_map, legend=False, ax=ax, legend_kwds={'loc': 'lower right'}, categories=categories)\n",
        "        \n",
        "        #Find boundary rectangle of 15x15 meters\n",
        "        gdf_rect, img_centre = bbox_rect(gdf_room)\n",
        "        #gdf_rect.boundary.plot(ax=ax, color='grey', linestyle=(5, (10, 3)), linewidth=1)\n",
        "        \n",
        "        #Get information about view landscape layer\n",
        "        view_nature = df_sim_room['view_landscape_nature_mean'].iloc[0]    \n",
        "        view_urban = df_sim_room['view_landscape_urban_mean'].iloc[0]\n",
        "        view_landscape = view_nature + view_urban\n",
        "        \n",
        "        # Only plot the diagram if the landscape layer is visible according to research \n",
        "        if view_landscape > 0.477: \n",
        "          #print(view_landscape)\n",
        "          #Get data for circle\n",
        "          radius = view_landscape/2.5\n",
        "          split_angle = ((view_nature/view_landscape) * 360) + 90\n",
        "\n",
        "          #print(f'total: {view_landscape}, nature: {view_nature} - {view_nature/view_landscape}%, urban: {view_urban}')\n",
        "\n",
        "          #Plot the view_landscape circle\n",
        "          circle_white = Wedge(center=img_centre, r=radius, theta1=0, theta2=360, facecolor='white', alpha=0.3)\n",
        "          ax.add_patch(circle_white)\n",
        "          circle_nature = Wedge(center=img_centre, r=radius, theta1=90, theta2=split_angle, facecolor='#AACFB5', alpha=0.4)\n",
        "          ax.add_patch(circle_nature)\n",
        "          circle_urban = Wedge(center=img_centre, r=radius, theta1=split_angle, theta2=450, facecolor='#CF8BA3', alpha=0.4)\n",
        "          ax.add_patch(circle_urban)\n",
        "\n",
        "\n",
        "        #set image settings\n",
        "        bounds = gdf_rect.total_bounds\n",
        "        ax.set_xlim(bounds[0], bounds[2])\n",
        "        ax.set_ylim(bounds[1], bounds[3])\n",
        "        ax.axis('off')\n",
        "\n",
        "        #Remove the borders of the plot\n",
        "        ax.spines['top'].set_visible(False)\n",
        "        ax.spines['right'].set_visible(False)\n",
        "        ax.spines['bottom'].set_visible(False)\n",
        "        ax.spines['left'].set_visible(False)\n",
        "\n",
        "\n",
        "        # Set the filename based on the site_id, app_id, and area_id\n",
        "        area_id1 = area_id.astype(int)\n",
        "        filename_png = f\"{app_id}_{area_id1}.png\"\n",
        "        filename_npy = f\"{app_id}_{area_id1}.npy\"\n",
        "        \n",
        "        # Save the plot to a PNG file with the specified filename and path\n",
        "        plt.savefig(os.path.join(path_png, filename_png), bbox_inches='tight', pad_inches=0, dpi=200)\n",
        "        plt.close(fig)\n",
        "\n",
        "        # Load the PNG image and save it as a NumPy array in the same folder\n",
        "        image_path = os.path.join(path_png, filename_png)\n",
        "        \n",
        "        # Open the image file using a with statement to ensure it's closed properly\n",
        "        with Image.open(image_path) as image:\n",
        "            # Resize the image to the needed size\n",
        "            new_size = (224, 224)\n",
        "            image = image.convert('RGB')\n",
        "            resized_image = image.resize(new_size)\n",
        "\n",
        "        #create and save the numpy array\n",
        "        image_array = np.array(resized_image)\n",
        "        numpy_save_path = os.path.join(path_npy_pred, filename_npy)\n",
        "        np.save(numpy_save_path, image_array)\n",
        "\n",
        "      else:\n",
        "        print('No simulation data')\n",
        "    else:\n",
        "      print('Empty room')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the path to the NumPy file you want to load\n",
        "path_npy_app = f'C:/Users/Name/OneDrive - Delft University of Technology/Building Technology-Thesis/10_Images_04Dataset_layouts/05_Room_Feature_v4_npy/3c3b1d6ca8b4b9092480b8c75f9eaa81_619322.npy'\n",
        "\n",
        "# Load the NumPy array\n",
        "loaded_array = np.load(path_npy_app)\n",
        "print(loaded_array.shape)\n",
        "# Create a Matplotlib figure and axis\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Plot the loaded NumPy array (assuming it represents an image)\n",
        "im = ax.imshow(loaded_array)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
